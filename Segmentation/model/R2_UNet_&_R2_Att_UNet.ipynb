{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D_Block(tf.keras.Sequential):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 num_conv_layers=2,\n",
    "                 kernel_size=(3,3),\n",
    "                 nonlinearity='relu',\n",
    "                 use_batchnorm = False,\n",
    "                 use_dropout = False,\n",
    "                 dropout_rate = 0.25, \n",
    "                 use_spatial_dropout = True,\n",
    "                 data_format='channels_last',\n",
    "                 **kwargs):\n",
    "\n",
    "        super(Conv2D_Block, self).__init__(**kwargs)\n",
    "\n",
    "        self.num_channels = num_channels\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_spatial_dropout = use_spatial_dropout\n",
    "        self.data_format = data_format\n",
    "\n",
    "        for i in range(self.num_conv_layers):\n",
    "            self.add(tf.keras.layers.Conv2D(self.num_channels, self.kernel_size, padding='same', data_format=self.data_format))\n",
    "            if self.use_batchnorm:\n",
    "              self.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.95, epsilon=0.001))\n",
    "            self.add(tf.keras.layers.Activation(self.nonlinearity))\n",
    "\n",
    "        if self.use_dropout:\n",
    "          if self.use_spatial_dropout:\n",
    "            self.add(tf.keras.layers.SpatialDropout2D(rate=self.dropout_rate))\n",
    "          else:\n",
    "            self.add(tf.keras.layers.Dropout(rate=self.dropout_rate))\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "\n",
    "        outputs = super(Conv2D_Block, self).call(inputs, training=training)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class Up_Conv2D(tf.keras.Sequential):\n",
    "\n",
    "    def __init__(self, \n",
    "                 num_channels,\n",
    "                 kernel_size=(2,2),\n",
    "                 nonlinearity='relu',\n",
    "                 use_batchnorm = False,\n",
    "                 use_transpose = False,\n",
    "                 strides=(2,2),\n",
    "                 data_format='channels_last',\n",
    "                 **kwargs):\n",
    "\n",
    "        super(Up_Conv2D, self).__init__(**kwargs)\n",
    "\n",
    "        self.num_channels = num_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.use_transpose = use_transpose\n",
    "        self.strides = strides\n",
    "        self.data_format = data_format\n",
    "\n",
    "        if self.use_transpose:\n",
    "          self.add(tf.keras.layers.Conv2DTranspose(self.num_channels, self.kernel_size, padding='same', strides=self.strides, data_format=self.data_format))\n",
    "        else:\n",
    "          self.add(tf.keras.layers.UpSampling2D(size=self.strides))\n",
    "          self.add(tf.keras.layers.Conv2D(self.num_channels, self.kernel_size, padding='same', data_format=self.data_format))\n",
    "        if self.use_batchnorm:\n",
    "          self.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.95, epsilon=0.001))\n",
    "        self.add(tf.keras.layers.Activation(self.nonlinearity))\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \n",
    "        outputs = super(Up_Conv2D, self).call(inputs, training=training)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class Recurrent_block(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 kernel_size=(3,3),\n",
    "                 strides=(1,1),\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 t=2,\n",
    "                 data_format='channels_last',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(Recurrent_block,self).__init__(**kwargs)\n",
    "        self.t = t\n",
    "        self.num_channels = num_channels\n",
    "        self.conv = Conv2D_Block(num_channels, num_conv_layers=1, kernel_size=kernel_size,nonlinearity=activation,use_batchnorm=True, use_dropout=False, dropout_rate=0.0, use_spatial_dropout=False,data_format=data_format)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for i in range(self.t):\n",
    "            if i==0:\n",
    "                x1 = self.conv(x, training=training)\n",
    "            output = self.conv(x+x1, training=training)\n",
    "        return output\n",
    "    \n",
    "        \n",
    "class RRCNN_block(tf.keras.Model):\n",
    "     def __init__(self,\n",
    "                 num_channels,\n",
    "                 kernel_size=(1,1),\n",
    "                 strides=(1,1),\n",
    "                 padding='same'\n",
    "                 nonlinearity='relu',\n",
    "                 t=2,\n",
    "                 data_format='channels_last',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(RRCNN_block,self).__init__(**kwargs)\n",
    "        \n",
    "        self.RCNN = tf.keras.Sequential([\n",
    "            Recurrent_block(num_channels,t=t),\n",
    "            Recurrent_block(num_channels,t=t)])\n",
    "        \n",
    "        self.Conv_1x1 = tf.keras.layers.Conv2D(num_channels,kernel_size,strides,padding,data_format)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.Conv_1x1(x)\n",
    "        x1 = self.RCNN(x)\n",
    "        output = x+x1\n",
    "        return output\n",
    "\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "\n",
    "class R2U_Net(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 output_ch=1,\n",
    "                 t=2,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(R2U_Net,self).__init__(**kwargs)\n",
    "        \n",
    "        self.RRCNN1 = RRCNN_block(num_channels=num_channels,t=t)\n",
    "        self.RRCNN2 = RRCNN_block(num_channels=num_channels*2,t=t)\n",
    "        self.RRCNN3 = RRCNN_block(num_channels=num_channels*4,t=t)\n",
    "        self.RRCNN4 = RRCNN_block(num_channels=num_channels*8,t=t)\n",
    "        self.RRCNN5 = RRCNN_block(num_channels=nm_channels*16,t=t)\n",
    "\n",
    "        self.Up5 = Up_Conv2D(num_channels=num_channels*8)\n",
    "        self.Up_RRCNN5 = RRCNN_block(num_channels=num_channels*8,t=t)\n",
    "        \n",
    "        self.Up4 = Up_Conv2D(num_channels=num_channels*4)\n",
    "        self.Up_RRCNN4 = RRCNN_block(num_channels=num_channels*4,t=t)\n",
    "        \n",
    "        self.Up3 = Up_Conv2D(num_channels=num_channels*2)\n",
    "        self.Up_RRCNN3 = RRCNN_block(num_channels=num_channels*2,t=t)\n",
    "        \n",
    "        self.Up2 = Up_Conv2D(num_channels=num_channels)\n",
    "        self.Up_RRCNN2 = RRCNN_block(num_channels=num_channels,t=t)\n",
    "\n",
    "        self.Conv_1x1 = tf.keras.layers.Conv2D(output_ch,kernel_size=(1,1),strides=(1,1),padding='same')\n",
    "\n",
    "        \n",
    "    def call(self,x, training=False):\n",
    "        # encoding path\n",
    "        x1 = self.RRCNN1(x, training=training)\n",
    "\n",
    "        x2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "        x2 = self.RRCNN2(x2, training=training)\n",
    "        \n",
    "        x3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "        x3 = self.RRCNN3(x3, training=training)\n",
    "\n",
    "        x4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "        x4 = self.RRCNN4(x4, training=training)\n",
    "\n",
    "        x5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x4)\n",
    "        x5 = self.RRCNN5(x5, training=training)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5, training=training)\n",
    "        d5 = tf.keras.layers.concatenatet([x4,d5])\n",
    "        d5 = self.Up_RRCNN5(d5, training=training)\n",
    "        \n",
    "        d4 = self.Up4(d5, training=training)\n",
    "        d4 = tf.keras.layers.concatenate([x3,d4])\n",
    "        d4 = self.Up_RRCNN4(d4, training=training)\n",
    "\n",
    "        d3 = self.Up3(d4, training=training)\n",
    "        d3 = tf.keras.layers.concatenate([x2,d3])\n",
    "        d3 = self.Up_RRCNN3(d3, training=training)\n",
    "\n",
    "        d2 = self.Up2(d3, training=training)\n",
    "        d2 = tf.keras.layers.concatenate([x1,d2])\n",
    "        d2 = self.Up_RRCNN2(d2, training=training)\n",
    "\n",
    "        output = self.Conv_1x1(d2)\n",
    "\n",
    "        return output\n",
    "\n",
    "    #--------------------------------------------------------------------------------------#\n",
    "    \n",
    "    class R2AttU_Net(tf.keras.Model):\n",
    "    \"\"\"Tensorflow 2 Implementation of 'U-Net: Convolutional Networks for Biomedical Image Segmentation'\n",
    "    https://arxiv.org/pdf/1804.03999.pdf. \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 num_channels,\n",
    "                 num_classes,\n",
    "                 num_conv_layers=1,\n",
    "                 kernel_size=(3,3),\n",
    "                 strides=(1,1),\n",
    "                 pool_size=(2,2),\n",
    "                 use_bias=False,\n",
    "                 padding='same',\n",
    "                 nonlinearity='relu',\n",
    "                 use_batchnorm = True,\n",
    "                 use_transpose = True,\n",
    "                 data_format='channels_last',\n",
    "                 **kwargs):\n",
    "\n",
    "        super(R2AttU_Net, self).__init__(**kwargs)\n",
    "\n",
    "        self.RRCNN1 = RRCNN_block(num_channels=num_channels,t=t)\n",
    "        self.RRCNN2 = RRCNN_block(num_channels=num_channels*2,t=t)\n",
    "        self.RRCNN3 = RRCNN_block(num_channels=num_channels*4,t=t)\n",
    "        self.RRCNN4 = RRCNN_block(num_channels=num_channels*8,t=t)\n",
    "        self.RRCNN5 = RRCNN_block(num_channels=nm_channels*16,t=t)\n",
    "\n",
    "        self.up_conv_1 = Up_Conv2D(num_channels*8,(3,3),nonlinearity,use_batchnorm=True,data_format=data_format)\n",
    "        self.up_conv_2 = Up_Conv2D(num_channels*4,(3,3),nonlinearity,use_batchnorm=True,data_format=data_format)\n",
    "        self.up_conv_3 = Up_Conv2D(num_channels*2,(3,3),nonlinearity,use_batchnorm=True,data_format=data_format)\n",
    "        self.up_conv_4 = Up_Conv2D(num_channels,(3,3),nonlinearity,use_batchnorm=True,data_format=data_format)\n",
    "\n",
    "        self.a1 = Attention_Gate(num_channels*8,(1,1),nonlinearity,padding,strides,use_bias,data_format)\n",
    "        self.a2 = Attention_Gate(num_channels*4,(1,1),nonlinearity,padding,strides,use_bias,data_format)\n",
    "        self.a3 = Attention_Gate(num_channels*2,(1,1),nonlinearity,padding,strides,use_bias,data_format)\n",
    "        self.a4 = Attention_Gate(num_channels,(1,1),nonlinearity,padding,strides,use_bias,data_format)\n",
    "\n",
    "        self.u1 = RRCNN_block(num_channels=num_channels*8,t=t)\n",
    "        self.u2 = RRCNN_block(num_channels=num_channels*4,t=t)\n",
    "        self.u3 = RRCNN_block(num_channels=num_channels*2,t=t)\n",
    "        self.u4 = RRCNN_block(num_channels=num_channels,t=t)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "\n",
    "        #ENCODER PATH\n",
    "        x1 = self.RRCNN1(inputs)\n",
    "        \n",
    "        pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "        x2 = self.RRCNN2(pool1)\n",
    "        \n",
    "        pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "        x3 = self.RRCNN3(pool2)\n",
    "        \n",
    "        pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "        x4 = self.RRCNN4(pool3)\n",
    "        \n",
    "        pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x4)\n",
    "        x5 = self.RRCNN5(pool4)\n",
    "\n",
    "        #DECODER PATH\n",
    "        up4 = self.up_conv_1(x5)\n",
    "        a1 = self.a1(up4, x4)\n",
    "        y1 = tf.keras.layers.concatenate([a1, up4])\n",
    "        y1 = self.u1(y1)\n",
    "\n",
    "        up5 = self.up_conv_2(y1)\n",
    "        a2 = self.a2(up5, x3)\n",
    "        y2 = tf.keras.layers.concatenate([a2, up5])\n",
    "        y2 = self.u2(y2)\n",
    "\n",
    "        up6 = self.up_conv_3(y2)\n",
    "        a3 = self.a3(up6, x2)\n",
    "        y3 = tf.keras.layers.concatenate([a3, up6])\n",
    "        y3 = self.u3(y3)\n",
    "\n",
    "        up7 = self.up_conv_4(y3)\n",
    "        a4 = self.a4(up7, x1)\n",
    "        y4 = tf.keras.layers.concatenate([a4, up7])\n",
    "        y4 = self.u4(y4)\n",
    "\n",
    "        output = self.conv_1x1(y4)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}